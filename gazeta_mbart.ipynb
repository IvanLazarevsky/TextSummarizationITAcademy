{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –ø—Ä–∏ –ø–æ–º–æ—â–∏ –º–æ–¥–µ–ª–∏ mBart. –ó–∞–º–µ—Ä—è–µ–º ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartTokenizer, MBartForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"IlyaGusev/mbart_ru_sum_gazeta\"\n",
    "tokenizer = MBartTokenizer.from_pretrained(model_name)\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 28 16:33:38 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 3090    Off  | 00000000:01:00.0  On |                  N/A |\r\n",
      "|  0%   55C    P2   137W / 350W |   5318MiB / 24265MiB |     60%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1110      G   /usr/lib/xorg/Xorg                 84MiB |\r\n",
      "|    0   N/A  N/A      1657      G   /usr/lib/xorg/Xorg                194MiB |\r\n",
      "|    0   N/A  N/A      1788      G   /usr/bin/gnome-shell              153MiB |\r\n",
      "|    0   N/A  N/A      2209      G   ...AAAAAAAAA= --shared-files       63MiB |\r\n",
      "|    0   N/A  N/A      3729      C   ...thon/general37/bin/python     4803MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBartForConditionalGeneration(\n",
      "  (model): MBartModel(\n",
      "    (shared): Embedding(250027, 1024, padding_idx=1)\n",
      "    (encoder): MBartEncoder(\n",
      "      (embed_tokens): Embedding(250027, 1024, padding_idx=1)\n",
      "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0): MBartEncoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): MBartEncoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): MBartEncoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): MBartEncoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): MBartEncoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): MBartEncoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (6): MBartEncoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (7): MBartEncoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (8): MBartEncoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (9): MBartEncoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (10): MBartEncoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (11): MBartEncoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): MBartDecoder(\n",
      "      (embed_tokens): Embedding(250027, 1024, padding_idx=1)\n",
      "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0): MBartDecoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): MBartDecoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): MBartDecoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): MBartDecoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): MBartDecoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): MBartDecoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (6): MBartDecoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (7): MBartDecoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (8): MBartDecoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (9): MBartDecoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (10): MBartDecoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (11): MBartDecoderLayer(\n",
      "          (self_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): MBartAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=250027, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAZETA_PATH = '../data/gazeta_jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gazeta_records(file_name, shuffle=False, sort_by_date=True):\n",
    "    assert shuffle != sort_by_date\n",
    "    records = []\n",
    "    with open(file_name, \"r\") as r:\n",
    "        for line in r:\n",
    "            records.append(json.loads(line))\n",
    "    if sort_by_date:\n",
    "        records.sort(key=lambda x: x[\"date\"])\n",
    "    if shuffle:\n",
    "        random.shuffle(records)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_files = {\n",
    "    'train': os.path.join(GAZETA_PATH,'gazeta_train.jsonl'),\n",
    "    'val': os.path.join(GAZETA_PATH,'gazeta_val.jsonl'),\n",
    "    'test': os.path.join(GAZETA_PATH, 'gazeta_test.jsonl')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {\n",
    "    split: read_gazeta_records(path) for split, path in dataset_files.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_text = records['val'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–ë—É–¥—É—â–µ–µ –∫–∞–ø–∏—Ç–∞–Ω–∞ –º–æ—Å–∫–æ–≤—Å–∫–æ–≥–æ ¬´–°–ø–∞—Ä—Ç–∞–∫–∞¬ª –î–µ–Ω–∏—Å–∞ –ì–ª—É—à–∞–∫–æ–≤–∞ –≤–µ—Å—å —ç—Ç–æ—Ç —Å–µ–∑–æ–Ω –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø–æ–¥–≤–µ—à–µ–Ω–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏, –∏, –ø–æ—Ö–æ–∂–µ, —Ä–∞–∑–≤—è–∑–∫–∞ —É–∂–µ –±–ª–∏–∑–∫–∞. –ö—Ä–∞—Å–Ω–æ-–±–µ–ª—ã—Ö –∂–¥–µ—Ç —Å–µ—Ä—å–µ–∑–Ω–∞—è –ø–µ—Ä–µ—Å—Ç—Ä–æ–π–∫–∞ –≤ –ª–µ—Ç–Ω–µ–µ —Ç—Ä–∞–Ω—Å—Ñ–µ—Ä–Ω–æ–µ –æ–∫–Ω–æ, –∏ –Ω–æ–≤–æ–º—É –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–º—É –¥–∏—Ä–µ–∫—Ç–æ—Ä—É –∫–æ–º–∞–Ω–¥—ã –¢–æ–º–∞—Å—É –¶–æ—Ä–Ω—É –ø–æ—Å—Ç–∞–≤–∏–ª–∏ –∑–∞–¥–∞—á—É –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –≤—ã–≥–æ–¥–Ω–æ —Ä–∞—Å—Å—Ç–∞—Ç—å—Å—è —Å –Ω–µ–∫–æ—Ç–æ—Ä—ã–º–∏ —Ñ—É—Ç–±–æ–ª–∏—Å—Ç–∞–º–∏ ‚Äî –≤ —Ç–æ–º —á–∏—Å–ª–µ –∏ —Å 32-–ª–µ—Ç–Ω–∏–º –ø–æ–ª—É–∑–∞—â–∏—Ç–Ω–∏–∫–æ–º, –∫–æ—Ç–æ—Ä—ã–π –æ—â—É—Ç–∏–º–æ —Å–¥–∞–ª –ø–æ –∏–≥—Ä–æ–≤—ã–º –∫–æ–Ω–¥–∏—Ü–∏—è–º –∏ –≤–ø–∞–ª –≤ –Ω–µ–º–∏–ª–æ—Å—Ç—å —É –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —Ñ–∞–Ω–∞—Ç–æ–≤ –∫–ª—É–±–∞ –∏–∑-–∑–∞ —Å–∫–∞–Ω–¥–∞–ª—å–Ω–æ–π —Å—Å–æ—Ä—ã —Å –ú–∞—Å—Å–∏–º–æ –ö–∞—Ä—Ä–µ—Ä–æ–π. –û–¥–Ω–∞–∫–æ –ø–æ –∫–æ–Ω—Ç—Ä–∞–∫—Ç—É —É –ì–ª—É—à–∞–∫–æ–≤–∞ –µ—â–µ –æ—Å—Ç–∞–µ—Ç—Å—è –≥–æ–¥ –∏–≥—Ä—ã –∑–∞ ¬´–°–ø–∞—Ä—Ç–∞–∫¬ª —Å –∑–∞—Ä–ø–ª–∞—Ç–æ–π 3 –º–ª–Ω –µ–≤—Ä–æ –≤ –≥–æ–¥, –∫–∞–∫ —Å–æ–æ–±—â–∞–µ—Ç ¬´–°–≠¬ª. –í —Å–ª—É—á–∞–µ –¥–æ—Å—Ä–æ—á–Ω–æ–≥–æ —Ä–∞—Å—Ç–æ—Ä–∂–µ–Ω–∏—è –∫–ª—É–± –¥–æ–ª–∂–µ–Ω –±—É–¥–µ—Ç –≤—ã–ø–ª–∞—Ç–∏—Ç—å —Ñ—É—Ç–±–æ–ª–∏—Å—Ç—É –ø–æ–ª–æ–≤–∏–Ω—É —ç—Ç–æ–π —Å—É–º–º—ã. –ò –≤–æ—Ç —Ç—É—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å–∞–º–æ–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ. –ê–¥–≤–æ–∫–∞—Ç –±—ã–≤—à–µ–π –∂–µ–Ω—ã –ì–ª—É—à–∞–∫–æ–≤–∞ –î–∞—Ä—å–∏ ‚Äî –°–µ—Ä–≥–µ–π –ñ–æ—Ä–∏–Ω ‚Äî –∑–∞—è–≤–∏–ª, —á—Ç–æ –µ–º—É –∫–∞–∂–µ—Ç—Å—è ¬´–æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–µ–π –Ω–∞ –ø—Ä–∞–≤–¥—É¬ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–æ–º, —á—Ç–æ —Ñ—É—Ç–±–æ–ª–∏—Å—Ç —è–∫–æ–±—ã –ø–æ–ø—Ä–æ—Å–∏–ª –∫–ª—É–± –æ—Ç–¥–∞—Ç—å –µ–º—É 1,5 –º–ª–Ω –Ω–∞–ª–∏—á–Ω—ã–º–∏, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –≤—ã–ø–ª–∞—Ç—ã –∞–ª–∏–º–µ–Ω—Ç–æ–≤. –ù–∞–ø–æ–º–Ω–∏–º, —Å—É–¥ –æ–±—è–∑–∞–ª —Ñ—É—Ç–±–æ–ª–∏—Å—Ç–∞ –≤—ã–ø–ª–∞—á–∏–≤–∞—Ç—å 1/3 –≤—Å–µ—Ö –¥–æ—Ö–æ–¥–æ–≤ –Ω–∞ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–≤—É—Ö –¥–æ—á–µ—Ä–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –æ—Å—Ç–∞–ª–∏—Å—å —Å –º–∞—Ç–µ—Ä—å—é. –ù–µ–æ–±—Ö–æ–¥–∏–º–∞—è —Å—É–º–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–ø–∏—Å—ã–≤–∞–ª–∞—Å—å —Å –∫–∞—Ä—Ç–æ—á–∫–∏ –∏–≥—Ä–æ–∫–∞ –ø—Ä–∏ –≤—ã–ø–ª–∞—Ç–µ –µ–º—É –∑–∞—Ä–ø–ª–∞—Ç—ã –∏ –ø–µ—Ä–µ–≤–æ–¥–∏–ª–∞—Å—å –Ω–∞ —Å—á–µ—Ç –∂–µ–Ω—ã. –ù–æ –µ—Å–ª–∏ –±—ã –∫–ª—É–± —Å–æ–≥–ª–∞—Å–∏–ª—Å—è –æ—Ç–¥–∞—Ç—å 1,5 –º–ª–Ω –Ω–∞–ª–∏—á–∫–æ–π, ¬´–ø–æ-—á–µ—Ä–Ω–æ–º—É¬ª, —Ç–æ —ç—Ç–∏ –¥–µ–Ω—å–≥–∏ –Ω–µ –±—ã–ª–∏ –±—ã –æ—Ç—Ä–∞–∂–µ–Ω—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –∫–ª—É–±–∞ –∏ –Ω–∞–ª–æ–≥–æ–≤–æ–π –¥–µ–∫–ª–∞—Ä–∞—Ü–∏–∏, –∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ, –∏–∑ –Ω–∏—Ö –Ω–µ –∏–∑–≤–ª–µ–∫–∞–ª–∞—Å—å –±—ã —Å—É–º–º–∞ –Ω–∞ –∞–ª–∏–º–µ–Ω—Ç—ã. –ö–∞–∫ –∏ –Ω–∞–ª–æ–≥–∏. ¬´–ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –∏–ª–∏ –æ–ø—Ä–æ–≤–µ—Ä–≥–Ω—É—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —è –Ω–µ –º–æ–≥—É, –ø–æ—Ç–æ–º—É —á—Ç–æ –Ω–µ –æ–±–ª–∞–¥–∞—é –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–º–∏ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞–º–∏, –Ω–æ —ç—Ç–æ –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–µ –Ω–∞ –ø—Ä–∞–≤–¥—É. –ö–∞–∫ –º–Ω–µ –∫–∞–∂–µ—Ç—Å—è, —ç—Ç–æ –≤ —Å—Ç–∏–ª–µ –î–µ–Ω–∏—Å–∞ –ì–ª—É—à–∞–∫–æ–≤–∞. –Ø –Ω–∞–¥–µ—é—Å—å, ¬´–°–ø–∞—Ä—Ç–∞–∫¬ª –Ω–µ –ø–æ–π–¥–µ—Ç –Ω–∞ —ç—Ç–∏ —É–ª–æ–≤–∫–∏ –∏ —É—Ö–∏—â—Ä–µ–Ω–∏—è, –ø–æ—Ç–æ–º—É —á—Ç–æ –¥–æ —ç—Ç–æ–≥–æ –º–æ–º–µ–Ω—Ç–∞ –∫–ª—É–± –≤–µ–ª —Å–µ–±—è –¥–æ—Å—Ç–æ–π–Ω–æ. –í—ã–ø–ª–∞—á–∏–≤–∞–µ—Ç –∞–ª–∏–º–µ–Ω—Ç—ã –∏ –∏—Å–ø–æ–ª–Ω—è–µ—Ç —Å—É–¥–µ–±–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è¬ª, ‚Äî –ø—Ä–∏–≤–æ–¥–∏—Ç —Å–ª–æ–≤–∞ –ñ–æ—Ä–∏–Ω–∞ Sport24. –¢–∞–∫–∂–µ –∞–¥–≤–æ–∫–∞—Ç –∑–∞–≤–µ—Ä–∏–ª, —á—Ç–æ –≤ –µ–≥–æ —Ä–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏–∏ –∏–º–µ–µ—Ç—Å—è –∫–æ–ø–∏—è –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞ –ì–ª—É—à–∞–∫–æ–≤–∞, —Ç–∞–∫ —á—Ç–æ, –µ—Å–ª–∏ —Ñ—É—Ç–±–æ–ª–∏—Å—Ç –Ω–∞ –±—É–º–∞–≥–µ –≤–¥—Ä—É–≥ –ø–æ–ª—É—á–∏—Ç –º–µ–Ω—å—à–µ –¥–µ–Ω–µ–≥, —á–µ–º –µ–º—É –ø–æ–ª–∞–≥–∞–µ—Ç—Å—è –ø–æ –¥–æ–≥–æ–≤–æ—Ä—É, –∏ –Ω–µ –±—É–¥–µ—Ç –≤–æ–∑—Ä–∞–∂–∞—Ç—å, —Ç–æ —ç—Ç–æ —Å—Ç–∞–Ω–µ—Ç –ø–æ–≤–æ–¥–æ–º –¥–ª—è –ø—Ä–∏—Å—Ç–∞–ª—å–Ω–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è. ¬´–í —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –º—ã –±—É–¥–µ–º –∑–∞–ø—Ä–∞—à–∏–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Å—É–¥–µ–±–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ –∏ –µ–µ –ø—Ä–æ–≤–µ—Ä—è—Ç—å. –ï—Å–ª–∏ –æ–Ω–∞ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—Å—è, —Ç–æ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä—è–¥ —É–≥–æ–ª–æ–≤–Ω—ã—Ö —Å–æ—Å—Ç–∞–≤–æ–≤, –Ω–∞—á–∏–Ω–∞—è –æ—Ç —É–∫–ª–æ–Ω–µ–Ω–∏—è —É–ø–ª–∞—Ç—ã –∞–ª–∏–º–µ–Ω—Ç–æ–≤, —É–º—ã—à–ª–µ–Ω–Ω–æ–≥–æ –Ω–µ–∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–µ—à–µ–Ω–∏—è —Å—É–¥–∞, –∏ –≤–ø–ª–æ—Ç—å –¥–æ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞¬ª, ‚Äî —Ü–∏—Ç–∏—Ä—É–µ—Ç –∞–¥–≤–æ–∫–∞—Ç–∞ ¬´–°–≠¬ª. –ü—Ä–∏ —ç—Ç–æ–º –ñ–æ—Ä–∏–Ω –æ—Ç–º–µ—Ç–∏–ª, —á—Ç–æ –µ–≥–æ –∫–ª–∏–µ–Ω—Ç–∫–∞ –î–∞—Ä—å—è —É–∂–µ –Ω–µ —É–¥–∏–≤–ª—è–µ—Ç—Å—è –ø–æ–¥–æ–±–Ω—ã–º –Ω–æ–≤–æ—Å—Ç—è–º –æ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø–ª–∞–Ω–∞—Ö —Å–≤–æ–µ–≥–æ –±—ã–≤—à–µ–≥–æ –º—É–∂–∞, –ø–æ—Å–∫–æ–ª—å–∫—É –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ –∑–Ω–∞–µ—Ç –µ–≥–æ –∫–∞–∫ –ª–∏—á–Ω–æ—Å—Ç—å. ¬´–Ø –¥—É–º–∞—é, —á—Ç–æ —Å –î–µ–Ω–∏—Å–æ–º –≤ ¬´–°–ø–∞—Ä—Ç–∞–∫–µ¬ª —Ä–∞—Å—Ç–æ—Ä–≥–∞—é—Ç –∫–æ–Ω—Ç—Ä–∞–∫—Ç ¬´–±–ª–∞–≥–æ–¥–∞—Ä—è¬ª –µ–≥–æ —Ö–∏—Ç—Ä–æ—Å—Ç—è–º –∏ –ø–æ–≤–µ–¥–µ–Ω–∏—é, –∞ –≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∏–¥—Ç–∏ –Ω–∞ –ø–æ–≤–æ–¥—É –ì–ª—É—à–∞–∫–æ–≤–∞ ‚Äî —ç—Ç–æ –Ω–µ—Ä–∞–∑—É–º–Ω–æ, –Ω–∞ –º–æ–π –≤–∑–≥–ª—è–¥¬ª, ‚Äî –ø–æ–¥—ã—Ç–æ–∂–∏–ª —é—Ä–∏—Å—Ç. –ü–æ—Å–ª–µ –ø–æ—è–≤–ª–µ–Ω–∏—è —ç—Ç–∏—Ö —Å–ª—É—Ö–æ–≤ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –Ω–∞ –∞–≤–∞–Ω—Å—Ü–µ–Ω—É –≤—ã—à–ª–∞ –∏ –∞–¥–≤–æ–∫–∞—Ç —Å–∞–º–æ–≥–æ –ì–ª—É—à–∞–∫–æ–≤–∞ ‚Äî –ú–∞—Ä–∏–Ω–∞ –î—É–±—Ä–æ–≤—Å–∫–∞—è. –î–µ–≤—É—à–∫–∞ –∑–∞–≤–µ—Ä–∏–ª–∞, —á—Ç–æ –µ–µ –ø–æ–¥–æ–ø–µ—á–Ω—ã–π –≤–æ–≤—Å–µ –Ω–µ —Å–æ–±–∏—Ä–∞–ª—Å—è –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø–æ–¥–æ–±–Ω–æ–π —Å—Ö–µ–º–æ–π. ¬´–ú—ã —É–∂–µ –ø—Ä–∏–≤—ã–∫–ª–∏ –∫ —Å–ª–∏–≤–∞–º –Ω–µ–ø—Ä–∞–≤–¥–∏–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã –æ–ø–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞ –æ–¥–Ω–∏—Ö –∏ —Ç–µ—Ö –∂–µ —Ä–µ—Å—É—Ä—Å–∞—Ö, –Ω–æ –∑–¥–µ—Å—å –æ–Ω–∏ –ø—Ä–µ–≤–∑–æ—à–ª–∏ —Å–∞–º–∏ —Å–µ–±—è. –ö–æ–Ω–µ—á–Ω–æ –∂–µ, –≤—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è—Ö –î–µ–Ω–∏—Å–∞ –∫ ¬´–°–ø–∞—Ä—Ç–∞–∫—É¬ª ‚Äî –ø–æ–ª–Ω–µ–π—à–∞—è –ª–æ–∂—å. –ò –≤ –∫–ª—É–±–µ –≤–∞–º –º–æ–≥—É—Ç —ç—Ç–æ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å¬ª, ‚Äî –∑–∞—è–≤–∏–ª–∞ —é—Ä–∏—Å—Ç–∫–∞. –ù–∞–ø–æ–º–Ω–∏–º, –Ω–∞—Å—Ç–æ–ª—å–∫–æ –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –≤–æ –≤–∑–≥–ª—è–¥–∞—Ö —É –ø—Ä–æ—Ç–∏–≤–æ–±–æ—Ä—Å—Ç–≤—É—é—â–∏—Ö —Å—Ç–æ—Ä–æ–Ω –ø—Ä–æ–∏—Å—Ö–æ–¥–∏–ª–∏ –∏ —Ä–∞–Ω–µ–µ. –¢–∞–∫, –∞–¥–≤–æ–∫–∞—Ç –∂–µ–Ω—ã –ì–ª—É—à–∞–∫–æ–≤–∞ –ñ–æ—Ä–∏–Ω –≤ –Ω–∞—á–∞–ª–µ –º–∞—è –∑–∞—è–≤–ª—è–ª, —á—Ç–æ —Ñ—É—Ç–±–æ–ª–∏—Å—Ç —è–∫–æ–±—ã –Ω–∞–ø–∏—Å–∞–ª –∑–∞—è–≤–ª–µ–Ω–∏–µ –≤ –§–µ–¥–µ—Ä–∞–ª—å–Ω—É—é —Å–ª—É–∂–±—É –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ ( –§–°–ë ) –∏ –∑–∞–ø—Ä–µ—Ç–∏–ª –≤—ã–ø—É—Å–∫–∞—Ç—å –µ–≥–æ –æ–±—â–µ–≥–æ —Å –î–∞—Ä—å–µ–π —Ä–µ–±–µ–Ω–∫–∞ –∑–∞ –≥—Ä–∞–Ω–∏—Ü—É. ¬´–ì–ª—É—à–∞–∫–æ–≤ —Ä–µ—à–∏–ª –æ—Ç–æ–º—Å—Ç–∏—Ç—å –∑–∞ —Ç–æ, —á—Ç–æ —Å—É–¥ –æ—Å—Ç–∞–≤–∏–ª –¥–µ—Ç–µ–π —Å –º–∞–º–æ–π –∏ –≤–∑—ã—Å–∫–∞–ª —Å –Ω–µ–≥–æ –∞–ª–∏–º–µ–Ω—Ç—ã. –ù–∞–∫–∞–Ω—É–Ω–µ –ø—Ä–∞–∑–¥–Ω–∏–∫–æ–≤ –æ–Ω –Ω–∞–ø–∏—Å–∞–ª –∑–∞—è–≤–ª–µ–Ω–∏–µ –≤ –§–°–ë —Å —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ–º –Ω–µ –≤—ã–ø—É—Å–∫–∞—Ç—å —Å—Ç–∞—Ä—à—É—é –¥–æ—á—å –∑–∞ –ø—Ä–µ–¥–µ–ª—ã –†–æ—Å—Å–∏–∏. –†–µ–±–µ–Ω–æ–∫ —É–∑–Ω–∞–ª –æ —Ç–æ–º, —á—Ç–æ –Ω–∏–∫—É–¥–∞ –Ω–µ –µ–¥–µ—Ç, –Ω–∞ –ø–∞—Å–ø–æ—Ä—Ç–Ω–æ–º –∫–æ–Ω—Ç—Ä–æ–ª–µ. –ú–æ–ª–æ–¥–µ—Ü, –î–µ–Ω–∏—Å!¬ª ‚Äî –Ω–∞–ø–∏—Å–∞–ª –ñ–æ—Ä–∏–Ω –≤ —Å–≤–æ–µ–º —Ç–≤–∏—Ç—Ç–µ—Ä–µ. –ó–∞–∫–æ–Ω –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–¥—É—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –Ω–∞–ø–∏—Å–∞—Ç—å –ø–æ–¥–æ–±–Ω–æ–µ –∑–∞—è–≤–ª–µ–Ω–∏–µ –≤ –ø–æ–≥—Ä–∞–Ω–∏—á–Ω—É—é —Å–ª—É–∂–±—É –§–°–ë, —á—Ç–æ–±—ã –ø—Ä–µ–¥—É–ø—Ä–µ–¥–∏—Ç—å —Ç–∞–∫–∏–µ —Å–ª—É—á–∞–∏, –∫–æ–≥–¥–∞ –æ–¥–∏–Ω –∏–∑ —Ä–æ–¥–∏—Ç–µ–ª–µ–π –ø—ã—Ç–∞–µ—Ç—Å—è —Ç–∞–π–∫–æ–º —É–≤–µ–∑—Ç–∏ —Ä–µ–±–µ–Ω–∫–∞ (–æ—Å–æ–±–µ–Ω–Ω–æ –µ—Å–ª–∏ —É –Ω–µ–≥–æ –µ—Å—Ç—å –≥—Ä–∞–∂–¥–∞–Ω—Å—Ç–≤–æ –¥—Ä—É–≥–æ–π —Å—Ç—Ä–∞–Ω—ã). ¬´–ü–æ –º–æ–µ–º—É –º–Ω–µ–Ω–∏—é, –ì–ª—É—à–∞–∫–æ–≤ –ø—Ä–æ—Å—Ç–æ –∑–ª–æ—É–ø–æ—Ç—Ä–µ–±–∏–ª —Å–≤–æ–∏–º –ø—Ä–∞–≤–æ–º, –∞ —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω–∞—è –ø–æ–≥—Ä–∞–Ω–∏—á–Ω–∞—è —Å–ª—É–∂–±–∞ –Ω–µ –æ–±—è–∑–∞–Ω–∞ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –º–µ—Ä, –ø–æ—Å–∫–æ–ª—å–∫—É –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏—à—å –Ω–∞–ø–∏—Å–∞—Ç—å –∑–∞—è–≤–ª–µ–Ω–∏–µ¬ª, ‚Äî –≤—ã—Å–∫–∞–∑–∞–ª—Å—è –ñ–æ—Ä–∏–Ω –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ ¬´–ß–µ–º–ø–∏–æ–Ω–∞—Ç.com¬ª. –ê–¥–≤–æ–∫–∞—Ç –ì–ª—É—à–∞–∫–æ–≤–∞ –î—É–±—Ä–æ–≤—Å–∫–∞—è —Ç–æ–≥–¥–∞ –æ–≥–ª–∞—Å–∏–ª–∞ —Å–≤–æ—é –≤–µ—Ä—Å–∏—é –ø—Ä–æ–∏—Å—Ö–æ–¥—è—â–µ–≥–æ. –ü–æ —Å–ª–æ–≤–∞–º —é—Ä–∏—Å—Ç–∫–∏, –î–∞—Ä—å—è ¬´—Å–æ —Å–≤–æ–∏–º –±–æ–π—Ñ—Ä–µ–Ω–¥–æ–º¬ª –ø—ã—Ç–∞–ª–∞—Å—å –≤—ã–≤–µ–∑—Ç–∏ –¥–µ—Ç–µ–π –≤ –î—É–±–∞–π –µ—â–µ –≤ —Å–∞–º–æ–º –Ω–∞—á–∞–ª–µ –±—Ä–∞–∫–æ—Ä–∞–∑–≤–æ–¥–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞. –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, —ç—Ç–æ –Ω–∞—Å—Ç–æ—Ä–æ–∂–∏–ª–æ —Ñ—É—Ç–±–æ–ª–∏—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ —Ö–æ—Ç–µ–ª –ª–∏—à–∞—Ç—å—Å—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ—Ç—å —Å–≤–æ–∏—Ö –¥–æ—á–µ—Ä–µ–π. ¬´–¢–æ–≥–¥–∞ –î–µ–Ω–∏—Å –Ω–∞–ø–∏—Å–∞–ª –∑–∞—è–≤–ª–µ–Ω–∏–µ –≤ –∞—ç—Ä–æ–ø–æ—Ä—Ç –∏ —É—Å—Ç–∞–Ω–æ–≤–∏–ª –∑–∞–ø—Ä–µ—Ç –Ω–∞ –≤—ã–µ–∑–¥ –¥–µ—Ç–µ–π. –î–∞—Ä—å—è –æ–± —ç—Ç–æ–º –∑–∞–ø—Ä–µ—Ç–µ –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ –∑–Ω–∞–ª–∞ –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ –ø–æ–ª—É–≥–æ–¥–∞. –ó–∞—á–µ–º –æ–Ω–∞ –ø–æ–≤–µ–∑–ª–∞ –¥–æ—á—å –≤ –∞—ç—Ä–æ–ø–æ—Ä—Ç, —á—Ç–æ–±—ã —Ç—Ä–∞–≤–º–∏—Ä–æ–≤–∞—Ç—å –µ–µ –ø—Å–∏—Ö–∏–∫—É, –Ω–∞–º —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ –Ω–µ –ø–æ–Ω—è—Ç–Ω–æ¬ª, ‚Äî –∑–∞—è–≤–∏–ª–∞ –î—É–±—Ä–æ–≤—Å–∫–∞—è –¢–ê–°–° , –ø—Ä–∏–±–∞–≤–∏–≤, —á—Ç–æ –ø–æ—Å–ª–µ –æ—Ç–∫–∞–∑–∞ –¥–æ—á–µ—Ä–∏ –Ω–∞ –≤—ã–µ–∑–¥ –î–∞—Ä—å—è —Å–ø–æ–∫–æ–π–Ω–æ –æ—Å—Ç–∞–≤–∏–ª–∞ —Ä–µ–±–µ–Ω–∫–∞ –≤ –†–æ—Å—Å–∏–∏ –∏ —É–ª–µ—Ç–µ–ª–∞ –æ—Ç–¥—ã—Ö–∞—Ç—å. –ö—Ç–æ –≤ —ç—Ç–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏ –ø—Ä–∞–≤, –∞ –∫—Ç–æ –≤–∏–Ω–æ–≤–∞—Ç, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–µ—à–∏—Ç–µ–ª—å–Ω–æ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ. –ê –ø–æ–∫–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è —Ç—Ä—É–¥–Ω—ã–π –±—Ä–∞–∫–æ—Ä–∞–∑–≤–æ–¥–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å, –≤ —Ö–æ–¥–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –ì–ª—É—à–∞–∫–æ–≤ –ø—ã—Ç–∞–µ—Ç—Å—è —Å–Ω–∏–∑–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∞–ª–∏–º–µ–Ω—Ç–æ–≤. –ö–∞–ø–∏—Ç–∞–Ω ¬´–°–ø–∞—Ä—Ç–∞–∫–∞¬ª –Ω–∞—Å—Ç–∞–∏–≤–∞–µ—Ç –Ω–∞ —Ç–æ–º, —á—Ç–æ–±—ã –ø–µ—Ä–µ—á–∏—Å–ª—è—Ç—å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—É–º–º—É –Ω–∞ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –±—ã–≤—à–µ–π —Å–µ–º—å–∏ ‚Äî 300 —Ç—ã—Å—è—á —Ä—É–±–ª–µ–π –≤ –º–µ—Å—è—Ü. –¢–∞–∫–∂–µ –∞–¥–≤–æ–∫–∞—Ç—ã —Ñ—É—Ç–±–æ–ª–∏—Å—Ç–∞ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏ –æ—à–∏–±–∫–∏ –≤ –ø—Ä–æ—Ç–æ–∫–æ–ª–µ –∑–∞—Å–µ–¥–∞–Ω–∏—è –≤ –ù–∏–∫—É–ª–∏–Ω—Å–∫–æ–º —Å—É–¥–µ, –∫–æ—Ç–æ—Ä—ã–π –æ–ø—Ä–µ–¥–µ–ª–∏–ª —Ä–∞–∑–º–µ—Ä –∞–ª–∏–º–µ–Ω—Ç–æ–≤. –ü–æ —ç—Ç–æ–π –ø—Ä–∏—á–∏–Ω–µ –¥–µ–ª–æ –±—ã–ª–æ –≤–Ω–æ–≤—å –≤–æ–∑–≤—Ä–∞—â–µ–Ω–æ –≤ —Ä–∞–π–æ–Ω–Ω—ã–π —Å—É–¥. ¬´–°—Ç–æ—Ä–æ–Ω–∞ –ì–ª—É—à–∞–∫–æ–≤–∞ –ø–æ–¥–∞–ª–∞ –∑–∞–º–µ—á–∞–Ω–∏–µ –Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª –∏ —Å–æ–ø—Ä–æ–≤–æ–¥–∏–ª–∞ —ç—Ç–æ –∑–∞—è–≤–ª–µ–Ω–∏–µ–º –æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å—Ä–æ–∫–∞. –ü–æ—Å–∫–æ–ª—å–∫—É —Å—Ä–æ–∫ –Ω–∞ –ø–æ–¥–∞—á—É —ç—Ç–∏—Ö –∑–∞–º–µ—á–∞–Ω–∏–π –±—ã–ª –ø—Ä–æ–ø—É—â–µ–Ω –ø–æ –æ–±—ä–µ–∫—Ç–∏–≤–Ω—ã–º –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤–∞–º, –±—ã–ª–æ –ø–æ–¥–∞–Ω–æ —ç—Ç–æ –∑–∞—è–≤–ª–µ–Ω–∏–µ. –ù–æ –ø–æ–¥–∞–Ω–æ –æ–Ω–æ –±—ã–ª–æ –ø–æ—Å–ª–µ –∞–ø–µ–ª–ª—è—Ü–∏–æ–Ω–Ω–æ–π –∂–∞–ª–æ–±—ã, –ø–æ—ç—Ç–æ–º—É –ú–æ—Å–∫–æ–≤—Å–∫–∏–π –≥–æ—Ä–æ–¥—Å–∫–æ–π —Å—É–¥ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ–ª–æ –≤ –ù–∏–∫—É–ª–∏–Ω—Å–∫–∏–π —Å—É–¥. –ü–æ—Å–ª–µ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è —Ç–∞–º –µ–≥–æ –æ–ø—è—Ç—å –≤–µ—Ä–Ω—É—Ç –≤ –ú–æ—Å–≥–æ—Ä—Å—É–¥. –î–µ–ª–æ –∑–∞—Ç—è–≥–∏–≤–∞–µ—Ç—Å—è¬ª, ‚Äî —Ü–∏—Ç–∏—Ä–æ–≤–∞–ª Sport24 –æ–¥–Ω–æ–≥–æ –∏–∑ –∞–¥–≤–æ–∫–∞—Ç–æ–≤ –î–∞—Ä—å–∏ –ê–ª–∏—Å—É –û–±—Ä–∞–∑—Ü–æ–≤—É. –î—Ä—É–≥–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Ö—Ä–æ–Ω–∏–∫–∏ , –∞ —Ç–∞–∫–∂–µ –≤ –≥—Ä—É–ø–ø–∞—Ö –æ—Ç–¥–µ–ª–∞ —Å–ø–æ—Ä—Ç–∞ –≤ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç—è—Ö Facebook –∏ ¬´–í–∫–æ–Ω—Ç–∞–∫—Ç–µ¬ª .'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/Programming/Python/general37/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3226: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ü§ó Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.prepare_seq2seq_batch(\n",
    "    [article_text],\n",
    "    src_lang=\"en_XX\", # fairseq training artifact\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=600\n",
    ")[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        input_ids=input_ids.cuda(),\n",
    "        max_length=162,\n",
    "        no_repeat_ngram_size=3,\n",
    "        num_beams=10,\n",
    "        top_k=0\n",
    "    )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = tokenizer.decode(output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞—â–∏—Ç–Ω–∏–∫ –º–æ—Å–∫–æ–≤—Å–∫–æ–≥–æ ¬´–°–ø–∞—Ä—Ç–∞–∫–∞¬ª –î–µ–Ω–∏—Å –ì–ª—É—à–∞–∫–æ–≤ –∑–∞—è–≤–∏–ª, —á—Ç–æ –µ–º—É –∫–∞–∂–µ—Ç—Å—è ¬´–æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–µ–π –Ω–∞ –ø—Ä–∞–≤–¥—É¬ª –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–æ–º, —á—Ç–æ —Ñ—É—Ç–±–æ–ª–∏—Å—Ç —è–∫–æ–±—ã –ø–æ–ø—Ä–æ—Å–∏–ª –∫–ª—É–± –æ—Ç–¥–∞—Ç—å –µ–º—É 1,5 –º–ª–Ω –Ω–∞–ª–∏—á–Ω—ã–º–∏, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –≤—ã–ø–ª–∞—Ç—ã –∞–ª–∏–º–µ–Ω—Ç–æ–≤.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(refs, hyps, metric=\"all\"):\n",
    "    metrics = dict()\n",
    "    metrics[\"count\"] = len(hyps)\n",
    "    metrics[\"ref_example\"] = refs[-1]\n",
    "    metrics[\"hyp_example\"] = hyps[-1]\n",
    "\n",
    "    if metric in (\"rouge\", \"all\"):\n",
    "        rouge = Rouge()\n",
    "        scores = rouge.get_scores(hyps, refs, avg=True)\n",
    "        metrics.update(scores)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(refs, hyps, metric=\"all\"):\n",
    "    metrics = calc_metrics(refs, hyps, metric=metric)\n",
    "\n",
    "    print(\"-------------METRICS-------------\")\n",
    "    print(\"Count:\\t\", metrics[\"count\"])\n",
    "    print(\"Ref:\\t\", metrics[\"ref_example\"])\n",
    "    print(\"Hyp:\\t\", metrics[\"hyp_example\"])\n",
    "\n",
    "#     if \"bleu\" in metrics:\n",
    "#         print(\"BLEU:     \\t{:3.1f}\".format(metrics[\"bleu\"] * 100.0))\n",
    "    if \"rouge-1\" in metrics:\n",
    "#         print([metrics[\"rouge-1\"][m] * 100.0 for m in ('p','r','f')])\n",
    "        print(\"ROUGE-1: P: {:3.2f} R: {:3.2f} F: {:3.2f}\".format(\n",
    "            *[metrics[\"rouge-1\"][m] * 100.0 for m in ['p','r','f']]))\n",
    "        print(\"ROUGE-2: P: {:3.2f} R: {:3.2f} F: {:3.2f}\".format(\n",
    "            *[metrics[\"rouge-2\"][m] * 100.0 for m in ['p','r','f']]))\n",
    "        print(\"ROUGE-L: P: {:3.2f} R: {:3.2f} F: {:3.2f}\".format(\n",
    "            *[metrics[\"rouge-l\"][m] * 100.0 for m in ['p','r','f']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(refs, hyps, tokenize_after=True, lower=True):\n",
    "    for i, (ref, hyp) in enumerate(zip(refs, hyps)):\n",
    "        ref = ref.strip()\n",
    "        hyp = hyp.strip()\n",
    "        if tokenize_after:\n",
    "            hyp = \" \".join([token.text for token in razdel.tokenize(hyp)])\n",
    "            ref = \" \".join([token.text for token in razdel.tokenize(ref)])\n",
    "        if lower:\n",
    "            hyp = hyp.lower()\n",
    "            ref = ref.lower()\n",
    "        refs[i] = ref\n",
    "        hyps[i] = hyp\n",
    "    return refs, hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_device(model):\n",
    "    return next(iter(model.parameters())).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_method_score(records, predict_func, nrows=None, return_ref_pred=False, text_key='text'):\n",
    "    references = []\n",
    "    predictions = []\n",
    "\n",
    "    for i, record in tqdm(enumerate(records)):\n",
    "        if nrows is not None and i >= nrows:\n",
    "            break\n",
    "        summary = record[\"summary\"]\n",
    "        text = record[text_key]\n",
    "        prediction = predict_func(text, summary)\n",
    "        references.append(summary)\n",
    "        predictions.append(prediction)\n",
    "    references, predictions = postprocess(references, predictions)\n",
    "    print_metrics(references, predictions)\n",
    "    if return_ref_pred:\n",
    "        return references, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π. –°–Ω–∏–∑—å—Ç–µ num_beams –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è (–º–æ–∂–µ—Ç –ø–æ–Ω–∏–∑–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ). –í –∫–∞—á–µ—Å—Ç–≤–µ refsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_bart(text):\n",
    "    input_ids = tokenizer.prepare_seq2seq_batch(\n",
    "        [text],\n",
    "        src_lang=\"en_XX\", # fairseq training artifact\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=600\n",
    "    )[\"input_ids\"]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids=input_ids.cuda(),\n",
    "            max_length=162,\n",
    "            no_repeat_ngram_size=3,\n",
    "            num_beams=10,\n",
    "            top_k=0\n",
    "        )[0]\n",
    "        \n",
    "        \n",
    "    summary = tokenizer.decode(output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–µ–Ω–∞—Ç–æ—Ä—ã –°–æ–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –®—Ç–∞—Ç–æ–≤ –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –≤–≤–µ—Å—Ç–∏ –ø—è—Ç—å –≤–∏–¥–æ–≤ —Å–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø—Ä–æ—Ç–∏–≤ —Ç–µ—Ö, –∫—Ç–æ —Å—Ç—Ä–∞—Ö—É–µ—Ç —Å—É–¥–∞, —É–∫–ª–∞–¥—ã–≤–∞—é—â–∏–µ ¬´–°–µ–≤–µ—Ä–Ω—ã–π –ø–æ—Ç–æ–∫ ‚Äî 2¬ª. –û–± —ç—Ç–æ–º —Å–æ–æ–±—â–∞–µ—Ç—Å—è –Ω–∞ —Å–∞–π—Ç–µ –∫–æ–Ω–≥—Ä–µ—Å—Å–∞. ¬´–ü—Ä–µ–∑–∏–¥–µ–Ω—Ç –º–æ–∂–µ—Ç –≤–≤–µ—Å—Ç–∏ –ø—è—Ç—å –∏–ª–∏ –±–æ–ª–µ–µ —Å–∞–Ω–∫—Ü–∏–π‚Ä¶ –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–∏ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω–æ–≥–æ –ª–∏—Ü–∞, –µ—Å–ª–∏ –æ–Ω —Ä–µ—à–∏—Ç, —á—Ç–æ —ç—Ç–æ –ª–∏—Ü–æ –æ—Å–æ–∑–Ω–∞–Ω–Ω–æ –≤ –¥–∞—Ç—É –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è —ç—Ç–æ–≥–æ –∑–∞–∫–æ–Ω–∞ –≤ —Å–∏–ª—É –∏–ª–∏ –ø–æ—Å–ª–µ –Ω–µ–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç —É—Å–ª—É–≥–∏ –ø–æ –æ—Ü–µ–Ω–∫–µ —Ä–∏—Å–∫–æ–≤, —Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏—é –∏–ª–∏ –ø–µ—Ä–µ—Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏—é —Å—É–¥–Ω—É¬ª, ‚Äî —É–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –≤ –∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç–µ. –ó–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç –ø—Ä–µ–¥—É—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç, —á—Ç–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –≤ –ø–µ—Ä–≤—É—é –æ—á–µ—Ä–µ–¥—å –±—É–¥—É—Ç –≤–≤–æ–¥–∏—Ç—å—Å—è –ø—Ä–æ—Ç–∏–≤ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç —Å–≤–æ–∏ —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—É–¥–∞ –¥–ª—è —É–∫–ª–∞–¥–∫–∏ –≥–∞–∑–æ–≤—ã—Ö —Ç—Ä—É–± –≤ –ë–∞–ª—Ç–∏–π—Å–∫–æ–º –º–æ—Ä–µ. –°—É–¥–∞ –¥–ª—è —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞ Nord Stream 2 –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç —Ç—Ä–∏ –∫–æ–º–ø–∞–Ω–∏–∏: —à–≤–µ–π—Ü–∞—Ä—Å–∫–∞—è Allseas, –∏—Ç–∞–ª—å—è–Ω—Å–∫–∞—è Saipem –∏ —Ä–æ—Å—Å–∏–π—Å–∫–∞—è –ú–†–¢–° (¬´–ú–µ–∂—Ä–µ–≥–∏–æ–Ω—Ç—Ä—É–±–æ–ø—Ä–æ–≤–æ–¥—Å—Ç—Ä–æ–π¬ª). –ü–æ–º–∏–º–æ —ç—Ç–æ–≥–æ —Å–∞–Ω–∫—Ü–∏–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤–≤–µ–¥–µ–Ω—ã –∏ –ø—Ä–æ—Ç–∏–≤ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –∏–ª–∏ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö –ª–∏—Ü, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–∑–Ω–∞—Ç–µ–ª—å–Ω–æ –æ–∫–∞–∑—ã–≤–∞—é—Ç —Å—Ç—Ä–∞—Ö–æ–≤—ã–µ –∏–ª–∏ –≥–∞—Ä–∞–Ω—Ç–∏–π–Ω—ã–µ —É—Å–ª—É–≥–∏ —ç—Ç–∏–º —Å—É–¥–∞–º. –ó–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç –æ–±—è–∂–µ—Ç —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –æ–±–æ –≤—Å–µ—Ö —É—á–∞—Å—Ç–Ω–∏–∫–∞—Ö —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –°–ü ‚Äî 2. –ò –µ—Å–ª–∏ —É—á–∞—Å—Ç–∏–µ –≤ –ø—Ä–æ–µ–∫—Ç–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è, —Ç–æ –°–®–ê –º–æ–≥—É—Ç –æ—Ç–∫–∞–∑–∞—Ç—å —Ç–∞–∫–∏–º –ª–∏—Ü–∞–º –≤ –≤—ã–¥–∞—á–µ –∏–ª–∏ –ø—Ä–æ–¥–ª–µ–Ω–∏–∏ –∫—Ä–µ–¥–∏—Ç–∞ –Ω–∞ –æ–±—â—É—é —Å—É–º–º—É –±–æ–ª–µ–µ $10 –º–ª–Ω –≤ —Ç–µ—á–µ–Ω–∏–µ –≥–æ–¥–∞. –ú–æ–∂–µ—Ç —Ç–∞–∫–∂–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç—å –æ—Ç–∫–∞–∑ –≤ –≤—ã–¥–∞—á–µ –ª–∏—Ü–µ–Ω–∑–∏–∏ –∏–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–∞ —ç–∫—Å–ø–æ—Ä—Ç –ª—é–±—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –∏–ª–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π —Ä–µ–≥—É–ª—è—Ç–æ—Ä–∞–º–∏ –°–®–ê. –ö—Ä–æ–º–µ —Ç–æ–≥–æ, –ø–µ—Ä–µ–¥ —Ä–∞–±–æ—Ç–∞—é—â–∏–º–∏ –Ω–∞–¥ –≥–∞–∑–æ–ø—Ä–æ–≤–æ–¥–æ–º –∫–æ–º–ø–∞–Ω–∏—è–º–∏ –º–∞—è—á–∏—Ç –∑–∞–ø—Ä–µ—Ç –Ω–∞ —Ä–∞–±–æ—Ç—É —Å –≥–æ—Å–¥–æ–ª–≥–æ–º –°–®–ê –∏–ª–∏ —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–º–∏ —Å—Ä–µ–¥—Å—Ç–≤–∞–º–∏ ¬´–≤ –∫–∞—á–µ—Å—Ç–≤–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –¥–∏–ª–µ—Ä–∞¬ª. –£—á–∞—Å—Ç–∏–µ –≤ –°–ü-2 –≥—Ä–æ–∑–∏—Ç –∑–∞–ø—Ä–µ—Ç–æ–º –Ω–∞ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –ø–ª–∞—Ç–µ–∂–µ–π –≤ –∑–æ–Ω–µ –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–π —é—Ä–∏—Å–¥–∏–∫—Ü–∏–∏ –∏ —Å–¥–µ–ª–æ–∫ —Å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é, –∑–∞–ø—Ä–µ—Ç–æ–º –∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ –∫–∞–ø–∏—Ç–∞–ª. –¢–∞–∫–∂–µ –ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ –°–æ–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –®—Ç–∞—Ç–æ–≤, –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ, –Ω–µ –º–æ–∂–µ—Ç –∑–∞–∫–ª—é—á–∞—Ç—å –∫–∞–∫–∏–µ-–ª–∏–±–æ –∫–æ–Ω—Ç—Ä–∞–∫—Ç—ã –Ω–∞ –∑–∞–∫—É–ø–∫—É —Ç–æ–≤–∞—Ä–æ–≤ –∏–ª–∏ —É—Å–ª—É–≥ —É –∑–∞–º–µ—à–∞–Ω–Ω–æ–≥–æ –≤ –ø—Ä–æ–µ–∫—Ç–µ –∏–Ω–æ—Å—Ç—Ä–∞–Ω–Ω–æ–≥–æ –ª–∏—Ü–∞. –î–∏—Ä–µ–∫—Ç–æ—Ä–∞–º –∏ –∞–∫—Ü–∏–æ–Ω–µ—Ä–∞–º —Å –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–º –ø–∞–∫–µ—Ç–æ–º –∞–∫—Ü–∏–π –≤ —Ç–∞–∫–∏—Ö –∫–æ–º–ø–∞–Ω–∏—è—Ö –º–æ–≥—É—Ç –æ—Ç–∫–∞–∑–∞—Ç—å –≤ –≤—ã–¥–∞—á–µ –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–π –≤–∏–∑—ã –∏ –∑–∞–ø—Ä–µ—Ç–∏—Ç—å –≤—ä–µ–∑–¥ –≤ –°–®–ê. –û—Ç–º–µ—á–∞–µ—Ç—Å—è, —á—Ç–æ –∞–≤—Ç–æ—Ä–∞–º–∏ –∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç–∞ —è–≤–ª—è—é—Ç—Å—è –î–∂–∏–Ω –®–∞—Ö–∏–Ω, –¢–µ–¥ –ö—Ä—É–∑ , –¢–æ–º –ö–æ—Ç—Ç–æ–Ω –∏ –î–∂–æ–Ω –ë–∞—Ä—Ä–∞—Å—Å–æ. –ß–µ—Ä–Ω–æ–≤–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç–∞ –±—ã–ª –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—è–º–∏ –æ–±–µ–∏—Ö –ø–∞—Ä–ª–∞–º–µ–Ω—Ç—Å–∫–∏—Ö –ø–∞—Ä—Ç–∏–π –µ—â–µ 14 –º–∞—è, —á—Ç–æ –ø–æ–≤—ã—à–∞–µ—Ç —à–∞–Ω—Å—ã –Ω–∞ –ø—Ä–∏–Ω—è—Ç–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞. –î–∂–∏–Ω –®–∞—Ö–∏–Ω ‚Äî –¥–µ–º–æ–∫—Ä–∞—Ç. –ê –¢–µ–¥ –ö—Ä—É–∑, –∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å–≤–æ–∏–º –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–º –æ—Ç–Ω–æ—à–µ–Ω–∏–µ–º –∫ –†–æ—Å—Å–∏–∏, —è–≤–ª—è–µ—Ç—Å—è —Ä–µ—Å–ø—É–±–ª–∏–∫–∞–Ω—Ü–µ–º –∏ —ç–∫—Å-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–º –≤ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç—ã –°–®–ê. –ö–∞–∫ —Ä–∞–Ω–µ–µ —Å–æ–æ–±—â–∞–ª–æ –∞–≥–µ–Ω—Ç—Å—Ç–≤–æ Bloomberg, –≥–ª–∞–≤–∞ –ú–∏–Ω—ç–Ω–µ—Ä–≥–æ –°–®–ê –†–∏–∫ –ü–µ—Ä—Ä–∏ –∑–∞—è–≤–∏–ª, —á—Ç–æ –í–∞—à–∏–Ω–≥—Ç–æ–Ω –ø–ª–∞–Ω–∏—Ä—É–µ—Ç –≤–≤–µ—Å—Ç–∏ —Å–∞–Ω–∫—Ü–∏–∏ –ø—Ä–æ—Ç–∏–≤ ¬´–°–µ–≤–µ—Ä–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞ ‚Äî 2¬ª. –û —Ç–∞–∫–∏—Ö –ø–ª–∞–Ω–∞—Ö –ü–µ—Ä—Ä–∏ –∑–∞—è–≤–∏–ª 21 –º–∞—è –≤–æ –≤—Ä–µ–º—è –≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏—è –≤ –ö–∏–µ–≤–µ. ¬´–ü–∞–ª–∞—Ç–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª–µ–π –∏ —Å–µ–Ω–∞—Ç, –∫–∞–∫ –æ–∂–∏–¥–∞–µ—Ç—Å—è, –ø–æ–¥–≥–æ—Ç–æ–≤—è—Ç –∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç –æ–± –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è—Ö –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–π, —É—á–∞—Å—Ç–≤—É—é—â–∏—Ö –≤ –ø—Ä–æ–µ–∫—Ç–µ Nord Stream 2¬ª, ‚Äî –ø—Ä–∏–≥—Ä–æ–∑–∏–ª –º–∏–Ω–∏—Å—Ç—Ä. –í–º–µ—Å—Ç–æ —Ä—É—Å—Å–∫–æ–≥–æ –≥–∞–∑–∞ —á–∏–Ω–æ–≤–Ω–∏–∫–∏ –∏–∑ –°–®–ê –ø—Ä–æ–¥–≤–∏–≥–∞—é—Ç –≤ –ï–≤—Ä–æ–ø—É —Å–≤–æ–π –°–ü–ì. –ò –¥–∞–∂–µ –Ω–∞–ø–æ–ª–Ω–∏–ª–∏ –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–π —Å–∂–∏–∂–µ–Ω–Ω—ã–π –≥–∞–∑ –º–µ—Ç–∞—Ñ–æ—Ä–∏—á–µ—Å–∫–∏–º —Å–º—ã—Å–ª–æ–º. –°–≤–æ–µ —Ç–æ–ø–ª–∏–≤–æ –æ–Ω–∏ –Ω–∞–∑—ã–≤–∞—é—Ç ¬´–º–æ–ª–µ–∫—É–ª—ã –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–π —Å–≤–æ–±–æ–¥—ã¬ª. –ù–∞ –≤–æ–ø—Ä–æ—Å: ¬´–ß–µ–º –ø–∞—Ö–Ω–µ—Ç —Å–≤–æ–±–æ–¥–∞?¬ª –º–∏–Ω–∏—Å—Ç–µ—Ä—Å—Ç–≤–æ —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏ –°–®–ê –æ—Ç–≤–µ—á–∞–µ—Ç —á–µ—Å—Ç–Ω–æ –∏ –ø—Ä—è–º–æ: –≥–∞–∑–æ–º. –í—ã—Å—Ç—É–ø–∞—è –≤ –í–∞–Ω–∫—É–≤–µ—Ä–µ –Ω–∞ –º–∏–Ω–∏—Å—Ç–µ—Ä—Å–∫–æ–π –≤—Å—Ç—Ä–µ—á–µ –ø–æ —á–∏—Å—Ç–æ–π —ç–Ω–µ—Ä–≥–∏–∏, –∑–∞–º–µ—Å—Ç–∏—Ç–µ–ª—å –º–∏–Ω–∏—Å—Ç—Ä–∞ —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏ –ú–∞—Ä–∫ –ú–µ–Ω–µ–∑–µ—Å –∑–∞—è–≤–∏–ª, —á—Ç–æ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —ç–∫—Å–ø–æ—Ä—Ç–∞ –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–≥–æ —Å–∂–∏–∂–µ–Ω–Ω–æ–≥–æ –ø—Ä–∏—Ä–æ–¥–Ω–æ–≥–æ –≥–∞–∑–∞ –∏–º–µ–µ—Ç ¬´—Ä–µ—à–∞—é—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –≥–∞–∑–∞ –ø–æ –≤—Å–µ–º—É –º–∏—Ä—É¬ª, –≤–µ–¥—å —Ç–∞–∫ —Ç–æ–≥–¥–∞ –≤–µ–∑–¥–µ –±—É–¥–µ—Ç ¬´–±–æ–ª–µ–µ —á–∏—Å—Ç—ã–π –≤–æ–∑–¥—É—Ö¬ª. –ü–æ—Å—Ç–∞–≤–∫–∏ –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–≥–æ –≥–∞–∑–∞ –Ω—É–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –¥–ª—è ¬´–æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –º–∏—Ä–∞ —á–∏—Å—Ç–æ–π —ç–Ω–µ—Ä–≥–∏–µ–π, –∞ —Ç–∞–∫–∂–µ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ —Å–æ—é–∑–Ω–∏–∫–æ–≤ –°–®–ê¬ª, –ø–æ–¥–¥–µ—Ä–∂–∞–ª –µ–≥–æ –ø–æ–º–æ—â–Ω–∏–∫ –º–∏–Ω–∏—Å—Ç—Ä–∞ —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏ –ø–æ –∏—Å–∫–æ–ø–∞–µ–º—ã–º –≤–∏–¥–∞–º —Ç–æ–ø–ª–∏–≤–∞ –°—Ç–∏–≤–µ–Ω –í–∏–Ω–±–µ—Ä–≥. ¬´–≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–ª–µ–∫—É–ª–∞–º –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–π —Å–≤–æ–±–æ–¥—ã —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è—Ç—å—Å—è –ø–æ –≤—Å–µ–º—É –º–∏—Ä—É¬ª, ‚Äî –ø–æ–¥—á–µ—Ä–∫–Ω—É–ª –í–∏–Ω–±–µ—Ä–≥. –ü–æ–∑–∂–µ –≤–µ–¥–æ–º—Å—Ç–≤–æ –ª–∏—Ä–∏—á–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã –æ–±–æ–∏—Ö –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª–æ –Ω–∞ —Å–≤–æ–µ–º —Å–∞–π—Ç–µ. –°–®–ê –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–≤–Ω–æ –∑–∞–∫—Ä–µ–ø–∏–ª–∏ –∑–∞ —Å–æ–±–æ–π –º–æ–Ω–æ–ø–æ–ª–∏—é –Ω–∞ ¬´—ç–∫—Å–ø–æ—Ä—Ç¬ª —Å–≤–æ–±–æ–¥—ã –∏ –¥–µ–º–æ–∫—Ä–∞—Ç–∏–∏ –≤–æ –≤—Å–µ–º –º–∏—Ä–µ, –ø–æ—ç—Ç–æ–º—É, –æ—á–µ–≤–∏–¥–Ω–æ, –≥–∞–∑, –¥–æ–±—ã–≤–∞–µ–º—ã–π –≤ —Å–∞–º–æ–º –¥–µ–º–æ–∫—Ä–∞—Ç–∏—á–µ—Å–∫–æ–º, –ø–æ –º–Ω–µ–Ω–∏—é –í–∞—à–∏–Ω–≥—Ç–æ–Ω–∞, –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ, –∏ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è —Å–≤–æ–±–æ–¥–Ω—ã–º, –æ—Ç–º–µ—á–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä –§–æ–Ω–¥–∞ —Ä–∞–∑–≤–∏—Ç–∏—è –ø—Ä–∞–≤–∞ –∏ –º–µ–¥–∏–∞—Ü–∏–∏ –¢–≠–ö –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –ü–∞—Ö–æ–º–æ–≤. ¬´–ï—Å–ª–∏ –æ—Ç–±—Ä–æ—Å–∏—Ç—å –≤–µ—Å—å –ø–∞—Ñ–æ—Å, —Ç–æ –º—ã –æ–±–Ω–∞—Ä—É–∂–∏–º, —á—Ç–æ –∑–∞ –Ω–∏–º —Å–∫—Ä—ã–≤–∞–µ—Ç—Å—è –≤–ø–æ–ª–Ω–µ —Ä–µ–∞–ª—å–Ω–∞—è –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–∞ –Ω–æ–≤–æ–≥–æ –≤–∏—Ç–∫–∞ —ç–∫—Å–ø–∞–Ω—Å–∏–∏ –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–≥–æ –°–ü–ì –Ω–∞ –º–∏—Ä–æ–≤–æ–π —Ä—ã–Ω–æ–∫¬ª, ‚Äî –∫–æ–Ω—Å—Ç–∞—Ç–∏—Ä—É–µ—Ç —ç–∫—Å–ø–µ—Ä—Ç. –° –∏—é–ª—è 2018 –≥–æ–¥–∞ –ø–æ—Å—Ç–∞–≤–∫–∏ –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–≥–æ –°–ü–ì –≤ –ï–≤—Ä–æ—Å–æ—é–∑ —É–≤–µ–ª–∏—á–∏–ª–∏—Å—å –Ω–∞ 272% ‚Äî –¥–æ 10,4 –º–∏–ª–ª–∏–∞—Ä–¥–∞ –∫—É–±–æ–º–µ—Ç—Ä–æ–≤. –ú–∏–Ω—É–≤—à–µ–π –∑–∏–º–æ–π –°–®–ê –∑–∞–Ω—è–ª–∏ —Ç—Ä–µ—Ç—å–µ –º–µ—Å—Ç–æ –ø–æ –æ–±—ä–µ–º—É –ø–æ—Å—Ç–∞–≤–æ–∫ –≤ –ï–° —Å –¥–æ–ª–µ–π 12,6%. –í –ø–µ—Ä–≤–æ–º –∫–≤–∞—Ä—Ç–∞–ª–µ —ç—Ç–æ–≥–æ –≥–æ–¥–∞ –ø–æ—Å—Ç–∞–≤–∫–∏ –°–ü–ì –∏–∑ –°–®–ê –Ω–∞ —ç–∫—Å–ø–æ—Ä—Ç —Å–æ—Å—Ç–∞–≤–∏–ª–∏ 10,2 –º–ª—Ä–¥ –∫—É–±. –º, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –≤ –ø–µ—Ä–≤–æ–º –∫–≤–∞—Ä—Ç–∞–ª–µ –ø—Ä–æ—à–ª–æ–≥–æ –≥–æ–¥–∞ 6,6 –º–ª—Ä–¥ –∫—É–±. –º ‚Äî —Ä–æ—Å—Ç –Ω–∞ 55%. –°–µ–π—á–∞—Å –≤ –°–®–ê —Ä–∞–±–æ—Ç–∞—é—Ç —Ç—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–Ω—ã—Ö –∑–∞–≤–æ–¥–∞ –°–ü–ì, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –≤ –ø–µ—Ä–≤–æ–º –∫–≤–∞—Ä—Ç–∞–ª–µ –ø—Ä–æ—à–ª–æ–≥–æ –≥–æ–¥–∞ ‚Äî —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω. –ï—â–µ —Ç—Ä–∏ –∑–∞–≤–æ–¥–∞ —Å–µ–π—á–∞—Å –Ω–∞—Ö–æ–¥—è—Ç—Å—è –Ω–∞ —Å—Ç–∞–¥–∏–∏ –≤–≤–æ–¥–∞ –≤ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—é, –∞ –¥–≤–∞ ‚Äî –≤ —Å—Ç–∞–¥–∏–∏ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞. –ú–æ—â–Ω–æ—Å—Ç—å —É–∂–µ —Ä–∞–±–æ—Ç–∞—é—â–∏—Ö –°–ü–ì –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Å–≤—ã—à–µ 40 –º–ª—Ä–¥ –∫—É–±. –º –≥–∞–∑–∞, –∞ –≤–º–µ—Å—Ç–µ —Å–æ —Å–¥–∞—é—â–∏–º–∏—Å—è –≤ —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—é –∏ —Å—Ç—Ä–æ—è—â–∏–º–∏—Å—è –≤—ã—Ä–∞—Å—Ç–µ—Ç –∫ 2025-–º—É –¥–æ —Å–≤—ã—à–µ 130 –º–ª—Ä–¥ –∫—É–±. –º –≥–∞–∑–∞, –æ—Ç–º–µ—á–∞–µ—Ç –∞–Ω–∞–ª–∏—Ç–∏–∫ –ø–æ –≥–∞–∑—É –¶–µ–Ω—Ç—Ä–∞ —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏ –ú–æ—Å–∫–æ–≤—Å–∫–æ–π —à–∫–æ–ª—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –°–∫–æ–ª–∫–æ–≤–æ –°–µ—Ä–≥–µ–π –ö–∞–ø–∏—Ç–æ–Ω–æ–≤. –ü—Ä–∞–≤–¥–∞, –º–µ—Ç–æ–¥—ã –ø—Ä–æ–¥–≤–∏–∂–µ–Ω–∏—è –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–æ–≥–æ –°–ü–ì –º–∞–ª–æ –∞—Å—Å–æ—Ü–∏–∏—Ä—É—é—Ç—Å—è —Å–æ —Å–ª–æ–≤–æ–º ¬´—Å–≤–æ–±–æ–¥–∞¬ª. –ù–∞ –µ–≤—Ä–æ–ø–µ–π—Å–∫–æ–º —Ä—ã–Ω–∫–µ —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ —Å–∏–ª—å–Ω—ã –ø–æ–∑–∏—Ü–∏–∏ –†–æ—Å—Å–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –¥–µ—Å—è—Ç–∏–ª–µ—Ç–∏—è–º–∏ –ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç—Ä—É–±–Ω—ã–π –≥–∞–∑ –≤ —Å—Ç—Ä–∞–Ω—ã –ï–°. –ê–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ —Å–≤–æ—é —ç–∫—Å–ø–∞–Ω—Å–∏—é –Ω–∞—á–∞–ª–∏ –Ω–µ —Ç–∞–∫ –¥–∞–≤–Ω–æ, –æ–¥–Ω–∞–∫–æ —ç—Ç–æ –¥–≤–∏–∂–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ –ø–æ–¥–∫—Ä–µ–ø–ª—è–µ—Ç—Å—è –Ω–∞ —É—Ä–æ–≤–Ω–µ –ë–µ–ª–æ–≥–æ –¥–æ–º–∞. –ü—Ä–µ–∑–∏–¥–µ–Ω—Ç –î–æ–Ω–∞–ª—å–¥ –¢—Ä–∞–º–ø –Ω–µ–æ–¥–Ω–æ–∫—Ä–∞—Ç–Ω–æ –∑–∞—è–≤–ª—è–ª –æ —Ç–æ–º, —á—Ç–æ –¥–ª—è —Å–≤–æ–µ–π —ç–Ω–µ—Ä–≥–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ï–° —Å—Ç–æ–∏—Ç –æ—Ç–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –æ—Ç —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö —ç–Ω–µ—Ä–≥–æ–Ω–æ—Å–∏—Ç–µ–ª–µ–π –≤ –ø–æ–ª—å–∑—É –ø–æ—Å—Ç–∞–≤–æ–∫ —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã —Å–æ—é–∑–Ω–∏–∫–æ–≤, —Ç–æ –µ—Å—Ç—å –°–®–ê.\n"
     ]
    }
   ],
   "source": [
    "print(records['val'][1]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ù–∏ –º–Ω–æ–≥–æ –Ω–∏ –º–∞–ª–æ, –∞ –ø—è—Ç—å –≤–∏–¥–æ–≤ —Å–∞–Ω–∫—Ü–∏–π –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –≤–≤–µ—Å—Ç–∏ –°–®–ê –ø—Ä–æ—Ç–∏–≤ —É—á–∞—Å—Ç–≤—É—é—â–∏—Ö –≤ —Ä–æ—Å—Å–∏–π—Å–∫–æ–º –ø—Ä–æ–µ–∫—Ç–µ ¬´–°–µ–≤–µ—Ä–Ω—ã–π –ø–æ—Ç–æ–∫ ‚Äî 2¬ª. –ó–∞–º–µ—à–∞–Ω–Ω—ã–º –≤ –°–ü ‚Äî 2 –∑–∞–ø—Ä–µ—Ç—è—Ç –ª—é–±—ã–µ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏, –≤ —Ç–æ–º —á–∏—Å–ª–µ –≤—ã–¥–∞—á—É –∫—Ä–µ–¥–∏—Ç–æ–≤. –í–∑–∞–º–µ–Ω —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ –≥–∞–∑–∞ –°–®–ê –ø—Ä–æ–¥–≤–∏–≥–∞—é—Ç ¬´–º–æ–ª–µ–∫—É–ª—ã —Å–≤–æ–±–æ–¥—ã¬ª ‚Äî —Å–≤–æ–π —Å–∂–∏–∂–µ–Ω–Ω—ã–π –ø—Ä–∏—Ä–æ–¥–Ω—ã–π –≥–∞–∑.\n"
     ]
    }
   ],
   "source": [
    "print(records['val'][1]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/Programming/Python/general37/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:3226: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of ü§ó Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ì–ª–∞–≤–∞ –ú–∏–Ω—ç–Ω–µ—Ä–≥–æ –°–®–ê –†–∏–∫ –ü–µ—Ä—Ä–∏ –∑–∞—è–≤–∏–ª, —á—Ç–æ –í–∞—à–∏–Ω–≥—Ç–æ–Ω –ø–ª–∞–Ω–∏—Ä—É–µ—Ç –≤–≤–µ—Å—Ç–∏ —Å–∞–Ω–∫—Ü–∏–∏ –ø—Ä–æ—Ç–∏–≤ –∫–æ–º–ø–∞–Ω–∏–π, —É—á–∞—Å—Ç–≤—É—é—â–∏—Ö –≤ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–µ –≥–∞–∑–æ–ø—Ä–æ–≤–æ–¥–∞ ¬´–°–µ–≤–µ—Ä–Ω—ã–π –ø–æ—Ç–æ–∫ ‚Äî 2¬ª. –ó–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç –ø—Ä–µ–¥—É—Å–º–∞—Ç—Ä–∏–≤–∞–µ—Ç –ø—è—Ç—å –≤–∏–¥–æ–≤ —Å–∞–Ω–∫—Ü–∏–æ–Ω–Ω—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –ø—Ä–æ—Ç–∏–≤ —Ç–µ—Ö, –∫—Ç–æ —Å—Ç—Ä–∞—Ö—É–µ—Ç —Å—É–¥–∞, —É–∫–ª–∞–¥—ã–≤–∞—é—â–∏–µ –≥–∞–∑–æ–≤—ã–µ —Ç—Ä—É–±—ã –≤ –ë–∞–ª—Ç–∏–π—Å–∫–æ–º –º–æ—Ä–µ. –ê–≤—Ç–æ—Ä–∞–º–∏ –∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç–∞ —è–≤–ª—è—é—Ç—Å—è –î–∂–∏–Ω –®–∞—Ö–∏–Ω, –¢–µ–¥ –ö—Ä—É–∑, –¢–æ–º –ö–æ—Ç—Ç–æ–Ω –∏ –î–∂–æ–Ω –ë–∞—Ä—Ä–∞—Å—Å–æ. –ß–µ—Ä–Ω–æ–≤–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –∑–∞–∫–æ–Ω–æ–ø—Ä–æ–µ–∫—Ç–∞ –±—ã–ª –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç–µ–ª—è–º–∏ –æ–±–µ–∏—Ö –ø–∞—Ä–ª–∞–º–µ–Ω—Ç—Å–∫–∏—Ö –ø–∞—Ä—Ç–∏–π –µ—â–µ 14 –º–∞—è, —á—Ç–æ –ø–æ–≤—ã—à–∞–µ—Ç —à–∞–Ω—Å—ã –Ω–∞ –ø—Ä–∏–Ω—è—Ç–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞.\n"
     ]
    }
   ],
   "source": [
    "print(predict_with_bart(records['val'][1]['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(4543)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b809efa61a6447c396cdaf592174a30a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------METRICS-------------\n",
      "Count:\t 70\n",
      "Ref:\t —É–∫—Ä–∞–∏–Ω—Å–∫–∞—è –ø–µ–≤–∏—Ü–∞ —Å–≤–µ—Ç–ª–∞–Ω–∞ –ª–æ–±–æ–¥–∞ –ø–æ–∂–∞–ª–æ–≤–∞–ª–∞—Å—å –ø–æ–¥–ø–∏—Å—á–∏–∫–∞–º –Ω–∞ –∂—É—Ç–∫–∏–µ –≥–µ–º–∞—Ç–æ–º—ã . —Å–æ–≥–ª–∞—Å–Ω–æ –∞—Ä—Ç–∏—Å—Ç–∫–µ , —Ç—Ä–∞–≤–º—ã —Å—Ç–∞–ª–∏ —Å–ª–µ–¥—Å—Ç–≤–∏–µ–º –µ–µ –∫–æ–Ω—Ü–µ—Ä—Ç–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ .\n",
      "Hyp:\t —É–∫—Ä–∞–∏–Ω—Å–∫–∞—è –ø–µ–≤–∏—Ü–∞ —Å–≤–µ—Ç–ª–∞–Ω–∞ –ª–æ–±–æ–¥–∞ –ø–æ–¥–µ–ª–∏–ª–∞—Å—å —Å –ø–æ–¥–ø–∏—Å—á–∏–∫–∞–º–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–µ–π —Å–≤–æ–∏—Ö –Ω–æ–≥ , –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –æ—Ç—á–µ—Ç–ª–∏–≤–æ –≤–∏–¥–Ω—ã –æ–≥—Ä–æ–º–Ω—ã–µ –≥–µ–º–∞—Ç–æ–º—ã . –ø–æ —Å–ª–æ–≤–∞–º 36-–ª–µ—Ç–Ω–µ–π —É—Ä–æ–∂–µ–Ω–∫–∏ –∫–∏–µ–≤–∞ , –¥–∞–Ω–Ω—ã–µ —Ç—Ä–∞–≤–º—ã —Å—Ç–∞–ª–∏ –ø—Ä—è–º—ã–º —Å–ª–µ–¥—Å—Ç–≤–∏–µ–º –µ–µ –∞–∫—Ç–∏–≤–Ω–æ–π –∫–æ–Ω—Ü–µ—Ä—Ç–Ω–æ–π –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ . —Ä–∞–Ω–µ–µ –≤ —Å–º–∏ –ø–æ—è–≤–∏–ª–∞—Å—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è , —á—Ç–æ –ª–∏–¥–µ—Ä –Ω–µ–º–µ—Ü–∫–æ–π –º–µ—Ç–∞–ª-–≥—Ä—É–ø–ø—ã rammstein —Ç–∏–ª–ª—å –ª–∏–Ω–¥–µ–º–∞–Ω–Ω —Å–ª–æ–º–∞–ª —á–µ–ª—é—Å—Ç—å –ø–æ–∫–ª–æ–Ω–Ω–∏–∫—É –∏–∑-–∑–∞ –¥–µ–≤—É—à–∫–∏ .\n",
      "ROUGE-1: P: 33.43 R: 38.19 F: 34.50\n",
      "ROUGE-2: P: 14.35 R: 16.64 F: 14.87\n",
      "ROUGE-L: P: 29.62 R: 33.25 F: 30.46\n"
     ]
    }
   ],
   "source": [
    "refs, preds = calc_method_score(random.sample(records['val'],70), \n",
    "                                lambda x,y: predict_with_bart(x), \n",
    "                                return_ref_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–≤–µ—Ä—Ö–æ–≤–Ω—ã–π —Å—É–¥ –µ—Å —Å–Ω—è–ª —Å–∞–Ω–∫—Ü–∏–∏ —Å —ç–∫—Å-–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ —É–∫—Ä–∞–∏–Ω—ã –≤–∏–∫—Ç–æ—Ä–∞ —è–Ω—É–∫–æ–≤–∏—á–∞ –∏ —à–µ—Å—Ç–∏ –µ–≥–æ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–Ω—ã—Ö . —Å—É–¥—å–∏ —Ä–µ—à–∏–ª–∏ , —á—Ç–æ –∑–∞–º–æ—Ä–∞–∂–∏–≤–∞–Ω–∏–µ –∏—Ö —Å—á–µ—Ç–æ–≤ –∏ –∞–∫—Ç–∏–≤–æ–≤ –±—ã–ª–æ –ø—Ä–æ–≤–µ–¥–µ–Ω–æ –≤ 2016-2018 –≥–æ–¥–∞—Ö –Ω–µ–∑–∞–∫–æ–Ω–Ω–æ . –æ–≥—Ä–∞–Ω–∏—á–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ä—ã –±—ã–ª–∏ —Å–Ω—è—Ç—ã –ø–æ –ø—Ä–∏—á–∏–Ω–µ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã—Ö –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤ —Ç–æ–≥–æ , —á—Ç–æ —á–∏–Ω–æ–≤–Ω–∏–∫–∏ –≤—ã–≤–æ–¥–∏–ª–∏ –ø–æ—Ö–∏—â–µ–Ω–Ω—ã–µ –≥–æ—Å—É–¥–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞ –∑–∞ —Ä—É–±–µ–∂ .\n"
     ]
    }
   ],
   "source": [
    "print(refs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–µ–≤—Ä–æ–ø–µ–π—Å–∫–∏–π —Å—É–¥ –æ—Ç–º–µ–Ω–∏–ª —Å–∞–Ω–∫—Ü–∏–∏ –≤ –æ—Ç–Ω–æ—à–µ–Ω–∏–∏ –±—ã–≤—à–µ–≥–æ –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç–∞ —É–∫—Ä–∞–∏–Ω—ã –≤–∏–∫—Ç–æ—Ä–∞ —è–Ω—É–∫–æ–≤–∏—á–∞ –∏ –µ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è , –æ—Ç–º–µ–Ω–∏–≤ —Ç–µ–º —Å–∞–º—ã–º —Ä–µ—à–µ–Ω–∏–µ –µ–≤—Ä–æ–ø–µ–π—Å–∫–æ–≥–æ —Å–æ–≤–µ—Ç–∞ –ø–æ –ø—Ä–æ–¥–ª–µ–Ω–∏—é —Å–∞–Ω–∫—Ü–∏–π –≤ –∏—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–∏ . –ø–æ –º–Ω–µ–Ω–∏—é —Å—É–¥–µ–π , –∑–∞–º–æ—Ä–∞–∂–∏–≤–∞–Ω–∏–µ —Å—á–µ—Ç–æ–≤ –∏ –∞–∫—Ç–∏–≤–æ–≤ –Ω–∞–∑–≤–∞–Ω–Ω—ã—Ö –ª–∏—Ü –≤ 2016-2018 –≥–æ–¥–∞—Ö –±—ã–ª–æ –Ω–µ–∑–∞–∫–æ–Ω–Ω—ã–º .\n"
     ]
    }
   ],
   "source": [
    "print(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bart_result.txt', 'w+') as f:\n",
    "    for ref, hyp in zip(refs, preds):\n",
    "        f.write(ref)\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(hyp)\n",
    "        f.write(\"\\n\\n=============\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
