{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAZETA_PATH = '../data/gazeta_jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gazeta_records(file_name, shuffle=False, sort_by_date=True):\n",
    "    assert shuffle != sort_by_date\n",
    "    records = []\n",
    "    with open(file_name, \"r\") as r:\n",
    "        for line in r:\n",
    "            records.append(json.loads(line))\n",
    "    if sort_by_date:\n",
    "        records.sort(key=lambda x: x[\"date\"])\n",
    "    if shuffle:\n",
    "        random.shuffle(records)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_files = {\n",
    "    'train': os.path.join(GAZETA_PATH,'gazeta_train.jsonl'),\n",
    "    'val': os.path.join(GAZETA_PATH,'gazeta_val.jsonl'),\n",
    "    'test': os.path.join(GAZETA_PATH, 'gazeta_test.jsonl')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {\n",
    "    split: read_gazeta_records(path) for split, path in dataset_files.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GPTSummarizer import GPTSummarizerPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предварительно нужно обучить модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTSummarizerPL.load_from_checkpoint('gpt_checkpoint_gazeta3/epoch=1-step=6549.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('sberbank-ai/rugpt3medium_based_on_gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_summary(model, text, max_input_length, max_output_length, **generate_args):\n",
    "    with torch.no_grad():\n",
    "        vocab=tokenizer.get_vocab()\n",
    "        bos_token_id = vocab['<s>']\n",
    "        eos_token_id = vocab['</s>']\n",
    "        pad_token_id = vocab['<pad>']\n",
    "        encoded_text = [bos_token_id] +\\\n",
    "            tokenizer.encode(text)[:max_input_length] + [eos_token_id]\n",
    "        encoded_text = torch.tensor(encoded_text, device=get_model_device(model)).view(1,-1)\n",
    "#         print(encoded_text.shape)\n",
    "        encoded_output = model.gpt.generate(encoded_text,\n",
    "                                            bos_token_id=bos_token_id,\n",
    "                                            eos_token_id=eos_token_id,\n",
    "                                            pad_token_id=pad_token_id,\n",
    "                                            max_length=max_input_length + max_output_length + 2,\n",
    "                                            **generate_args)\n",
    "\n",
    "        indices = encoded_output[0].tolist()\n",
    "\n",
    "        first_eos_index = indices.index(eos_token_id)\n",
    "        sum_start_index = first_eos_index + 1\n",
    "\n",
    "        final_indices = []\n",
    "#         print(indices[first_eos_index:])\n",
    "        final_indices = indices[sum_start_index:-1]\n",
    "#         for idx in indices[sum_start_index:]:\n",
    "#             if idx != eos_token_id:\n",
    "#                 final_indices.append(idx)\n",
    "#             else:\n",
    "#                 break\n",
    "    return tokenizer.decode(final_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(refs, hyps, metric=\"all\"):\n",
    "    metrics = dict()\n",
    "    metrics[\"count\"] = len(hyps)\n",
    "    metrics[\"ref_example\"] = refs[-1]\n",
    "    metrics[\"hyp_example\"] = hyps[-1]\n",
    "\n",
    "    if metric in (\"rouge\", \"all\"):\n",
    "        rouge = Rouge()\n",
    "        scores = rouge.get_scores(hyps, refs, avg=True)\n",
    "        metrics.update(scores)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(refs, hyps, metric=\"all\"):\n",
    "    metrics = calc_metrics(refs, hyps, metric=metric)\n",
    "\n",
    "    print(\"-------------METRICS-------------\")\n",
    "    print(\"Count:\\t\", metrics[\"count\"])\n",
    "    print(\"Ref:\\t\", metrics[\"ref_example\"])\n",
    "    print(\"Hyp:\\t\", metrics[\"hyp_example\"])\n",
    "\n",
    "#     if \"bleu\" in metrics:\n",
    "#         print(\"BLEU:     \\t{:3.1f}\".format(metrics[\"bleu\"] * 100.0))\n",
    "    if \"rouge-1\" in metrics:\n",
    "#         print([metrics[\"rouge-1\"][m] * 100.0 for m in ('p','r','f')])\n",
    "        print(\"ROUGE-1: P: {:3.2f} R: {:3.2f} F: {:3.2f}\".format(\n",
    "            *[metrics[\"rouge-1\"][m] * 100.0 for m in ['p','r','f']]))\n",
    "        print(\"ROUGE-2: P: {:3.2f} R: {:3.2f} F: {:3.2f}\".format(\n",
    "            *[metrics[\"rouge-2\"][m] * 100.0 for m in ['p','r','f']]))\n",
    "        print(\"ROUGE-L: P: {:3.2f} R: {:3.2f} F: {:3.2f}\".format(\n",
    "            *[metrics[\"rouge-l\"][m] * 100.0 for m in ['p','r','f']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(refs, hyps, tokenize_after=True, lower=True):\n",
    "    for i, (ref, hyp) in enumerate(zip(refs, hyps)):\n",
    "        ref = ref.strip()\n",
    "        hyp = hyp.strip()\n",
    "        if tokenize_after:\n",
    "            hyp = \" \".join([token.text for token in razdel.tokenize(hyp)])\n",
    "            ref = \" \".join([token.text for token in razdel.tokenize(ref)])\n",
    "        if lower:\n",
    "            hyp = hyp.lower()\n",
    "            ref = ref.lower()\n",
    "        refs[i] = ref\n",
    "        hyps[i] = hyp\n",
    "    return refs, hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_device(model):\n",
    "    return next(iter(model.parameters())).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_method_score(records, predict_func, nrows=None, return_ref_pred=False, text_key='text'):\n",
    "    references = []\n",
    "    predictions = []\n",
    "\n",
    "    for i, record in tqdm(enumerate(records)):\n",
    "        if nrows is not None and i >= nrows:\n",
    "            break\n",
    "        summary = record[\"summary\"]\n",
    "        text = record[text_key]\n",
    "        prediction = predict_func(text, summary)\n",
    "        references.append(summary)\n",
    "        predictions.append(prediction)\n",
    "    references, predictions = postprocess(references, predictions)\n",
    "    print_metrics(references, predictions)\n",
    "    if return_ref_pred:\n",
    "        return references, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_gpt(text, summary):\n",
    "    summary = extract_summary(model, text, 601, 163,\n",
    "            no_repeat_ngram_size=3,\n",
    "            num_beams=10,\n",
    "            top_k=0,\n",
    "            early_stopping=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5770"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(records['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3534\n",
      "Отношения Германии и США переживают не лучшие времена, разногласия по политическим и экономическим вопросам и угрозы со стороны Вашингтона оказали негативный эффект на взаимодействие двух стран. Об этом пишет журнал Der Spiegel. По данным аналитиков издания, в настоящее время 85% граждан ФРГ негативно или резко негативно относятся к США, а 42% считают ключевым партнером Китай. Одной из причин ухудшения отношений Берлина с Вашингтоном стало назначение посла США в ФРГ Ричарда Гренелла. Дипломат занял данный пост в мае 2018 года, и с тех пор «стороны играют в молчанку». Немецкие чиновники постепенно начали избегать любых встреч с Гренеллом , в частности, канцлер Германии Ангела Меркель ни разу с ним не общалась, пишет журнал. Власти ФРГ начали игнорировать посла США из-за его поведения. К примеру, дипломат фактически оборвал контакты с организацией «Атлантический мост», которая является ключевой в диалоге Берлина и Вашингтона. Также Гренелл не раз выступал с критикой в адрес правительства Германии, жестко высказывая позицию США. Эксперты журнала считают, что в настоящее время отношения Берлина и Вашингтона «оказались на дне». Германия и США не могут прийти к соглашению по ряду политических и экономических вопросов. В частности, стороны придерживаются разных позиций в отношении иранской ядерной сделки. Дело в том, что в 2018 году Вашингтон покинул соглашение, заявив, что оно не отвечает его интересам. Президент США Дональд Трамп неоднократно говорил о необходимости заключения нового договора. В то же время Берлин настаивает на сохранении сделки. Совместный всеобъемлющий план действий по ядерной программе (СВДП) Ирана был согласован еще в 2015 году. Договор предусматривал постановку ядерной программы Ирана под контроль МАГАТЭ в обмен на снятие санкций. Группа 5+1 первоначально состояла из США, России, КНР, Великобритании и Франции — пяти постоянных членов Совбеза ООН , а также Германии. Вашингтон покинул соглашение и вновь ввел санкции в отношении Тегерана, действия США не устраивают всех остальных участников договора. Ситуация вокруг ядерной сделки обострилась в 2019 году, когда Иран приостановил выполнение двух пунктов — превысил значение запасов низкообогащенного урана и начал процесс обогащения на уровне выше предусмотренного соглашением. В то же время Берлин и Вашингтон спорят не только из-за Ирана, предметом разногласий также являются торговые пошлины Трампа. Президент США ввел пошлины на импорт стали и алюминия из ряда стран еще в прошлом году. Свою экономическую политику Трамп объясняет защитой интересов нацбезопасности США. Он также настаивает на заключении нового торгового соглашения с Евросоюзом в обмен на отмену пошлин. Жесткие действия Трампа не устраивают Германию, которая выступает за свободные торговые отношения между ЕС и США. При этом основательно «поссорил» Германию с США газопровод «Северный поток — 2». Берлин изначально поддерживает проект и настаивает на необходимости его реализации. В свою очередь Вашингтон критикует «Северный поток — 2», который якобы угрожает безопасности и независимости Европы. В спорах ФРГ и США по данному вопросу не последнюю роль сыграл американский посол. Дело в том, что Гренелл начал угрожать представителям немецкого бизнеса санкциями за участие в проекте. В Германии охарактеризовали действия посла как вмешательство во внутренние дела страны. Однако главной причиной разногласий между Берлином и Вашингтоном является вопрос финансирования НАТО. США обвиняют страны Евросоюза в том, что они тратят недостаточно средств на оборону. Вашингтон требует от Германии и других стран ЕС поднять расходы на оборону до 2% ВВП. В свою очередь Берлин пока не собирается выполнять данное требование. Отказ Германии от повышения расходов на оборону раскритиковал посол США. В частности, Гренелл пригрозил выводом войск США из Германии. При этом официальный Берлин просто проигнорировал резонансное заявление посла США.\n",
      "-----------\n",
      "Reference\n",
      "\n",
      "Отношения Германии и США «оказались на дне» из-за разногласий по ряду политических и экономических вопросов. По данным СМИ, не последнюю роль в происходящем сыграл посол США Ричард Гренелл. Дипломат известен своей критикой в адрес властей ФРГ.\n",
      "\n",
      "Generated\n",
      "\n",
      "Немецкие СМИ пишут, что отношения между Германией и США находятся на дне. 85% населения страны негативно или жестко высказываются по отношению к США. Конфликт между Вашингтоном и Берлином обострился после того, как посол США Ричард Гренелл был назначен послом в ФРГ.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    rand_index = random.randrange(len(records['val']))\n",
    "    rand_index = 3534\n",
    "    print(rand_index)\n",
    "    text = records['val'][rand_index]['text']\n",
    "    print(text)\n",
    "    print(\"-----------\")\n",
    "    ref = records['val'][rand_index]['summary']\n",
    "    print(\"Reference\\n\")\n",
    "    \n",
    "    print(ref)\n",
    "    print(\"\\nGenerated\\n\")\n",
    "    \n",
    "    print(extract_summary(model,text, 600,163,\n",
    "            no_repeat_ngram_size=3,\n",
    "            num_beams=10,\n",
    "            top_k=0,\n",
    "            early_stopping=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(4543)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181356ed8ec84335b9dfa3e9443ecafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------METRICS-------------\n",
      "Count:\t 70\n",
      "Ref:\t украинская певица светлана лобода пожаловалась подписчикам на жуткие гематомы . согласно артистке , травмы стали следствием ее концертной деятельности .\n",
      "Hyp:\t певица света лобода рассказала о травмах , полученных во время выступлений на сцене . согласно артистке , в 2011 году она выступала с концертами в москве , нижнем новгороде и других городах .\n",
      "ROUGE-1: P: 29.29 R: 20.34 F: 23.29\n",
      "ROUGE-2: P: 6.30 R: 4.18 F: 4.85\n",
      "ROUGE-L: P: 25.44 R: 17.51 F: 20.29\n"
     ]
    }
   ],
   "source": [
    "refs, preds = calc_method_score(random.sample(records['val'],70), predict_with_gpt, return_ref_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gpt_result.txt', 'w+') as f:\n",
    "    for ref, hyp in zip(refs, preds):\n",
    "        f.write(ref)\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(hyp)\n",
    "        f.write(\"\\n\\n=============\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
